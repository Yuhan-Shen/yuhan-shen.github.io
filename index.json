[{"authors":["admin"],"categories":null,"content":"Yuhan Shen is a PhD student in Computer Science in Khoury College of Computer Sciences at Northeastern University, Boston, MA. He is working on the intersection of computer vision and natural language processing, co-advised by Professor Ehsan Elhamifar and Professor Lu Wang. Before joining Northeastern University, he received his bachelor\u0026rsquo;s degree from Department of Electronic Engineering at Tsinghua University in China in 2018. He also worked as a research assistant in Speech and Audio Lab at Tsinghua University under the guidance of Professor Wei-Qiang Zhang.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1557161651,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://yuhan.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Yuhan Shen is a PhD student in Computer Science in Khoury College of Computer Sciences at Northeastern University, Boston, MA. He is working on the intersection of computer vision and natural language processing, co-advised by Professor Ehsan Elhamifar and Professor Lu Wang. Before joining Northeastern University, he received his bachelor\u0026rsquo;s degree from Department of Electronic Engineering at Tsinghua University in China in 2018. He also worked as a research assistant in Speech and Audio Lab at Tsinghua University under the guidance of Professor Wei-Qiang Zhang.","tags":null,"title":"Yuhan Shen","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a36058eafe01cd26b16c80f89806a069","permalink":"https://yuhan.github.io/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/skills/","section":"","summary":"","tags":null,"title":"Skills","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4f5622892cf36115c4fd6a9793b9c9d1","permalink":"https://yuhan.github.io/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/accomplishments/","section":"","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"49cbbfcf1124f111a37fcbac0faeb48e","permalink":"https://yuhan.github.io/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/","section":"","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1f9ddd144499ee8fae766f749d13434","permalink":"https://yuhan.github.io/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/featured/","section":"","summary":"","tags":null,"title":"Featured Publications","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"97f061f6e721d99ff473e04294bd8fcf","permalink":"https://yuhan.github.io/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tags/","section":"","summary":"","tags":null,"title":"Popular Topics","type":"page"},{"authors":[],"categories":[],"content":"","date":1569644939,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569644939,"objectID":"274e07a4cdb0449f6dab5a2f3798d117","permalink":"https://yuhan.github.io/post/neu/","publishdate":"2019-09-28T00:28:59-04:00","relpermalink":"/post/neu/","section":"post","summary":"","tags":[],"title":"[2019/09] Starting PhD program at Northeastern University","type":"post"},{"authors":["Yu-Han Shen","Ke-Xin He","Wei-Qiang Zhang"],"categories":[],"content":"","date":1568505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568505600,"objectID":"10841c6862e2c73e0baf8a38fd5e3d39","permalink":"https://yuhan.github.io/publication/interspeech2019_shen/","publishdate":"2019-09-28T00:39:49-04:00","relpermalink":"/publication/interspeech2019_shen/","section":"publication","summary":"In this paper, we propose a temporal-frequential attention model for sound event detection (SED). Our network learns how to listen with two attention models: a temporal attention model and a frequential attention model. Proposed system learns when to listen using the temporal attention model while it learns where to listen on the frequency axis using the frequential attention model. With these two models, we attempt to make our system pay more attention to important frames or segments and important frequency components for sound event detection. Our proposed method is demonstrated on the task 2 of Detection and Classification of Acoustic Scenes and Events (DCASE) 2017 Challenge and outperforms state-of-the-art methods.","tags":[],"title":"Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection","type":"publication"},{"authors":["Ke-Xin He*","Yu-Han Shen*","Wei-Qiang Zhang"],"categories":[],"content":"","date":1568436901,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568436901,"objectID":"7a6cdc9a91b7cdb06f32fc21a1aba06a","permalink":"https://yuhan.github.io/publication/interspeech2019_he/","publishdate":"2019-09-14T00:55:01-04:00","relpermalink":"/publication/interspeech2019_he/","section":"publication","summary":"Sound event detection with weakly labeled data is considered as a problem of multi-instance learning. And the choice of pooling function is the key to solving this problem. In this paper, we proposed a hierarchical pooling structure to improve the performance of weakly labeled sound event detection system. Proposed pooling structure has made remarkable improvements on three types of pooling function without adding any parameters. Moreover, our system has achieved competitive performance on Task 4 of Detection and Classification of Acoustic Scenes and Events (DCASE) 2017 Challenge using hierarchical pooling structure.","tags":[],"title":"Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection","type":"publication"},{"authors":[],"categories":[],"content":"","date":1566518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566518400,"objectID":"5a1f44a21db693507019a955a3752ff7","permalink":"https://yuhan.github.io/post/dcase2019/","publishdate":"2019-08-23T00:00:00Z","relpermalink":"/post/dcase2019/","section":"post","summary":"","tags":[],"title":"[2019/08] One paper is accepted by DCASE Workshop 2019","type":"post"},{"authors":[],"categories":[],"content":"","date":1563667200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563667200,"objectID":"f212621d1ec3d57b4391246d782ecb08","permalink":"https://yuhan.github.io/post/dcase2019_challenge/","publishdate":"2019-07-21T00:00:00Z","relpermalink":"/post/dcase2019_challenge/","section":"post","summary":"","tags":[],"title":"[2019/07] Won the 2nd place in Task 2 of DCASE Challenge 2019","type":"post"},{"authors":["Kexin He*","Yuhan Shen*","Wei-Qiang Zhang"],"categories":[],"content":"This is a task of the Detection and Classification of Acoustic Scenes and Events (DCASE) Challenge 2019. It aims to develop a well-performed audio tagging system using a small amount of manually-labeled data and a large quantity of noisy-labeled data. We took part in this competition and won the 2nd place. To achieve state-of-the-art performance, we mainly adopted the following strategies:\n We used mixup and SpecAugment for data augmentation. We designed a sigmoid-softmax activation structure to deal with sparse multi-label classification. We proposed a staged training strategy to learn from nose data. We applied post-processing method that normalizes output scores for each sound class. We adopted ensemble method that averages models learned with multiple neural networks and acoustic features.  ","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"315c8e78b70fb969c42d503130907ac0","permalink":"https://yuhan.github.io/project/audio_tagging/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/project/audio_tagging/","section":"project","summary":"Developed a well-performed audio tagging system using a small amount of manually-labeled data and a large quantity of noisy-labeled data. ","tags":["Audio"],"title":"Audio tagging with noisy labels and minimal supervision","type":"project"},{"authors":[],"categories":[],"content":"","date":1560729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560729600,"objectID":"33fc739bcc711e6fc1ae3cf2dc3b4845","permalink":"https://yuhan.github.io/post/interspeech2019/","publishdate":"2019-06-17T00:00:00Z","relpermalink":"/post/interspeech2019/","section":"post","summary":"","tags":[],"title":"[2019/06] Two papers are accepted by Interspeech 2019","type":"post"},{"authors":["Yuhan Shen","Kexin He","Wei-Qiang Zhang"],"categories":[],"content":"We propose a temporal-frequential attention model for sound event detection (SED). Our network learns how to listen with two attention models: a temporal attention model and a frequential attention model. Proposed system learns when to listen using the temporal attention model while it learns where to listen on the frequency axis using the frequential attention model. With these two models, we attempt to make our system pay more attention to important frames or segments and important frequency components for sound event detection. Our proposed method is demonstrated on the task 2 of Detection and Classification of Acoustic Scenes and Events (DCASE) 2017 Challenge and outperforms state-of-the-art methods.\n","date":1545264000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545264000,"objectID":"6df55ffda114cc5d9eecc78d3fa1551e","permalink":"https://yuhan.github.io/project/sound_event_detection/","publishdate":"2018-12-20T00:00:00Z","relpermalink":"/project/sound_event_detection/","section":"project","summary":"Detected rare sound events with high precision and recall based on deep neural networks and attention models.","tags":["Audio"],"title":"Rare sound event detection","type":"project"},{"authors":["Yu-Han Shen","Ke-Xin He","Wei-Qiang Zhang"],"categories":[],"content":"","date":1544054400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544054400,"objectID":"ed9b9529c6164cce139084c619b055bd","permalink":"https://yuhan.github.io/publication/isspit2018/","publishdate":"2018-12-06T00:00:00Z","relpermalink":"/publication/isspit2018/","section":"publication","summary":"In this paper, we propose a method for home activity monitoring. We demonstrate our model on dataset of Detection and Classification of Acoustic Scenes and Events (DCASE) 2018 Challenge Task 5. This task aims to classify multi-channel audios into one of the provided pre-defined classes. All of these classes are daily activities performed in a home environment. To tackle this task, we propose a gated convolutional neural network with segment-level attention mechanism (SAM-GCNN). The proposed framework is a convolutional model with two auxiliary modules: a gated convolutional neural network and a segment-level attention mechanism. Furthermore, we adopted model ensemble to enhance the capability of generalization of our model. We evaluated our work on the development dataset of DCASE 2018 Task 5 and achieved competitive performance, with a macro-averaged F-1 score increasing from 83.76% to 89.33%, compared with the convolutional baseline system.","tags":[],"title":"SAM-GCNN: A Gated Convolutional Neural Network with Segment-Level Attention Mechanism for Home Activity Monitoring","type":"publication"}]