<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yuhan Shen</title>
    <link>https://yuhan-shen.github.io/</link>
      <atom:link href="https://yuhan-shen.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Yuhan Shen</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2019 Yuhan Shen</copyright><lastBuildDate>Sat, 19 Jun 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yuhan-shen.github.io/img/icon-192.png</url>
      <title>Yuhan Shen</title>
      <link>https://yuhan-shen.github.io/</link>
    </image>
    
    <item>
      <title>Skills</title>
      <link>https://yuhan-shen.github.io/skills/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/skills/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Accomplish&amp;shy;ments</title>
      <link>https://yuhan-shen.github.io/accomplishments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/accomplishments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent &amp; Upcoming Talks</title>
      <link>https://yuhan-shen.github.io/talks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/talks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Featured Publications</title>
      <link>https://yuhan-shen.github.io/featured/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/featured/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Popular Topics</title>
      <link>https://yuhan-shen.github.io/tags/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/tags/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unsupervised Procedure Learning from Visual and Language Instructions via Differentiable Weak Sequence Alignment</title>
      <link>https://yuhan-shen.github.io/publication/cvpr2021/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/publication/cvpr2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[2021/03] One paper is accepted to CVPR 2021</title>
      <link>https://yuhan-shen.github.io/post/cvpr2021/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/post/cvpr2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Staged Training Strategy and Multi-Activation for Audio Tagging with Noisy and Sparse Multi-Label Data</title>
      <link>https://yuhan-shen.github.io/publication/icassp2020/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/publication/icassp2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[2020/01] One paper is accepted by ICASSP 2020</title>
      <link>https://yuhan-shen.github.io/post/icassp2020/</link>
      <pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/post/icassp2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[2019/10] Travelled to New York City to attend DCASE Workshop 2019</title>
      <link>https://yuhan-shen.github.io/post/dcase2019_workshop/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/post/dcase2019_workshop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple Neural Networks with Ensemble Method for Audio Tagging with Noisy Labels and Minimal Supervision</title>
      <link>https://yuhan-shen.github.io/content/publication/he-2019/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/content/publication/he-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiple Neural Networks with Ensemble Method for Audio Tagging with Noisy Labels and Minimal Supervision</title>
      <link>https://yuhan-shen.github.io/publication/dcase2019_he/</link>
      <pubDate>Tue, 01 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/publication/dcase2019_he/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-modal Procedure Learning for Video Summarization</title>
      <link>https://yuhan-shen.github.io/project/video_summarization/</link>
      <pubDate>Sat, 28 Sep 2019 16:20:53 -0400</pubDate>
      <guid>https://yuhan-shen.github.io/project/video_summarization/</guid>
      <description>&lt;p&gt;&lt;DIV align = &#34;justify&#34;&gt;
This is my first PhD project. The goal is to summarize the key steps of instructional videos from both visual and language data using unsupervised procedure learning.
&lt;/DIV&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[2019/09] Starting PhD program at Northeastern University</title>
      <link>https://yuhan-shen.github.io/post/neu/</link>
      <pubDate>Sat, 28 Sep 2019 00:28:59 -0400</pubDate>
      <guid>https://yuhan-shen.github.io/post/neu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection</title>
      <link>https://yuhan-shen.github.io/publication/interspeech2019_shen/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/publication/interspeech2019_shen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hierarchical Pooling Structure for Weakly Labeled Sound Event Detection</title>
      <link>https://yuhan-shen.github.io/publication/interspeech2019_he/</link>
      <pubDate>Sat, 14 Sep 2019 00:55:01 -0400</pubDate>
      <guid>https://yuhan-shen.github.io/publication/interspeech2019_he/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[2019/08] One paper is accepted to DCASE Workshop 2019</title>
      <link>https://yuhan-shen.github.io/post/dcase2019/</link>
      <pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/post/dcase2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>[2019/07] Won the 2nd place in Task 2 of DCASE Challenge 2019</title>
      <link>https://yuhan-shen.github.io/post/dcase2019_challenge/</link>
      <pubDate>Sun, 21 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/post/dcase2019_challenge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Audio Tagging with Noisy Labels and Minimal Supervision</title>
      <link>https://yuhan-shen.github.io/project/audio_tagging/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/project/audio_tagging/</guid>
      <description>&lt;p&gt;&lt;DIV align = &#34;justify&#34;&gt;
This is a task of the Detection and Classification of Acoustic Scenes and Events (DCASE) Challenge 2019. It aims to develop a well-performed audio tagging system using a small amount of manually-labeled data and a large quantity of noisy-labeled data. We took part in this competition and won the 2nd place. To achieve state-of-the-art performance, we mainly adopted the following strategies:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We used mixup and SpecAugment for data augmentation.&lt;/li&gt;
&lt;li&gt;We designed a sigmoid-softmax activation structure to deal with sparse multi-label classification.&lt;/li&gt;
&lt;li&gt;We proposed a staged training strategy to learn from nose data.&lt;/li&gt;
&lt;li&gt;We applied post-processing method that normalizes output scores for each sound class.&lt;/li&gt;
&lt;li&gt;We adopted ensemble method that averages models learned with multiple neural networks and acoustic features.
&lt;/DIV&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>[2019/06] Two papers are accepted to Interspeech 2019</title>
      <link>https://yuhan-shen.github.io/post/interspeech2019/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/post/interspeech2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research on Sound Event Detection</title>
      <link>https://yuhan-shen.github.io/project/sound_event_detection/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/project/sound_event_detection/</guid>
      <description>&lt;p&gt;&lt;DIV align = &#34;justify&#34;&gt;
My contributions and achievements go as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Proposed a bi-domain (on both time domain and frequency domain) attention model for rare sound event detection.&lt;/li&gt;
&lt;li&gt;Proposed a hierarchical pooling structure for weakly-labeled sound event detection.&lt;/li&gt;
&lt;li&gt;Outperformed state-of-the-art methods on evaluation dataset of Task 2 and Task 4 of Detection and Classification of Acoustic Events and Scenes (DCASE) 2017.&lt;/li&gt;
&lt;li&gt;Two Papers published in Proceedings of Interspeech 2019 as first or co-first author.
&lt;/DIV&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>SAM-GCNN: A Gated Convolutional Neural Network with Segment-Level Attention Mechanism for Home Activity Monitoring</title>
      <link>https://yuhan-shen.github.io/publication/isspit2018/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://yuhan-shen.github.io/publication/isspit2018/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
